{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## GPT 2 Fine-tuned with Equal length Stories Model Story Generation\n",
        "\n",
        "Here the stories were made to be equal length by repeating their content to match the approximate size of the longest story. Which in this case was the Three Musketeers."
      ],
      "metadata": {
        "id": "Ze8eEtJoQ8ZR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Last modified: 06-01-2024\n",
        "\n",
        "Name: Mahamuge Dinendra Nadishan Costa\n",
        "\n",
        "UWE Student Number: 13030224"
      ],
      "metadata": {
        "id": "1QGPssVK2vbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install the required library updates for both accelerate and transformers\n",
        "#from huggingface\n",
        "!pip install -U accelerate\n",
        "!pip install -U transformers\n",
        "\n",
        "# This resets the environment automatically to apply the installations above.\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "D1VpeGY64zR5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc166ef2-d436-46fd-f96a-3a69b8b4ba32"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.36.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wymba1qWOpa9",
        "outputId": "9b117f61-eac6-4b69-c662-8d12f4d67703"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the device to CUDA (or GPU) for processing\n",
        "import torch\n",
        "\n",
        "device = torch.device(\n",
        "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "print(f'Using Device: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkLJiI6Z43EN",
        "outputId": "332bcc36-aad1-4da7-bc26-389105e9d9e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the required GPT2 modules from the transformers library for running\n",
        "#GPT2 model\n",
        "from transformers import GPT2Tokenizer,GPT2LMHeadModel,TrainingArguments,Trainer,DataCollatorWithPadding\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "\n",
        "# If a local copy of the fine-tuned model is unavailable, use the following two lines to load the model and tokenizer to load it directly from Huggingface:\n",
        "\n",
        "# tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n",
        "# model = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\")\n",
        "\n",
        "\n",
        "\n",
        "# Run the following to load the fine-tuned model on stories with original lengths\n",
        "# tokenizer = GPT2Tokenizer.from_pretrained(\"/content/drive/MyDrive/Colab Notebooks/Story Gen/GPT 2 Finetuned/tokenizer\")\n",
        "# model = GPT2LMHeadModel.from_pretrained(\"/content/drive/MyDrive/Colab Notebooks/Story Gen/GPT 2 Finetuned/model\")\n",
        "\n",
        "\n",
        "# Run following two lines to load the fine tuned model trained on equivalent length stories\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"/content/drive/MyDrive/Colab Notebooks/Story Gen/GPT 2 Finetuned with data balance/tokenizer\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"/content/drive/MyDrive/Colab Notebooks/Story Gen/GPT 2 Finetuned with data balance/model\")\n",
        "\n",
        "\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "  tokenizer.pad_token = tokenizer.eos_token\n",
        "  tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "#Send the model to process within the GPU\n",
        "model.cuda()"
      ],
      "metadata": {
        "id": "jWua4ZciFQMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "288b8622-5f28-4aea-dd39-80b7d28cef5b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 1024)\n",
              "    (wpe): Embedding(1024, 1024)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-23): 24 x GPT2Block(\n",
              "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the fine-tuned model with 10 prompts"
      ],
      "metadata": {
        "id": "V5XRuOSkyZcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the model to evaluate to run prompts on the model for generation\n",
        "model.eval()\n",
        "\n",
        "#Set prompt text for model\n",
        "prompt_text = \"He drew his sword and pointed at the peculiar\"\n",
        "\n",
        "#Convert the prompt text to tokens and add the attention mask\n",
        "input_ids = tokenizer(prompt_text, return_tensors = \"pt\").input_ids\n",
        "attention_mask = tokenizer(\n",
        "    prompt_text, return_tensors=\"pt\"\n",
        ").attention_mask\n",
        "\n",
        "#Send converted prompt and attention mask to GPU\n",
        "input_ids = input_ids.to(device)\n",
        "attention_mask = attention_mask.to(device)\n",
        "\n",
        "\n",
        "#Generate the output from the model based on the parameter set here\n",
        "output = model.generate(\n",
        "    input_ids = input_ids,\n",
        "    attention_mask = attention_mask,\n",
        "    pad_token_id = tokenizer.pad_token_id,\n",
        "    max_length = 1024,\n",
        "    num_beams = 10,\n",
        "    min_length = 1000,\n",
        "    temperature = 3.5,\n",
        "    top_k = 50,\n",
        "    do_sample = True,\n",
        ")\n",
        "\n",
        "\n",
        "generated_text = tokenizer.decode(output[0],skip_special_tokens = True)\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4d7e47d-a9cb-4dc2-b241-c23d0897de75",
        "id": "dbFxstTi02-A"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He drew his sword and pointed at the peculiar humped brow of his companion, with a smile on his part of which, not only he but some of the passengers could perceive, he took a fresh countenance, and endeavored a sort of grimace to soften some of the wrinkles on his brow of which he had made his famous appearance before Lord de Winter; at the instant a fresh cloud burst over his brow which betrayed, with a certain obscurity, that he had not yet seen Felton appear in the person of the pretended liberator, he rose, and went back to the street where his master and Bazin were at the moment in conversation with Milady, who was leaning over him, at the windows of the saloon, where they saw the street door closed upon Lord de Winter, who had returned to the Place Royale to find the letter, and from which he had been escaping with a vengeance, and whom he had endeavored to find a servant who betrayed himself by the orders of the king so that he might deliver the queen some fine words in which he would extricate D’Artagnan from the hands of the cardinal, when, instead of meeting the queen on her first return, he found himself, or rather seeing her at the Louvre, in this charming place with his enemy and in the presence of the two Musketeers who had so long awaited, as Bazin said to D’Artagnan, on a threshold, as is said of the queen, and from which he concluded that the queen was ignorant of what was taking place within the city walls.” “She is in a fright, D’Artagnan,” said Milady; “but as you speak of that letter, we must be at the risk of scandalizing you; but I beg you be so kind as to say that we will take good care of you,” and she looked toward the Rue des Fossoyeurs and the Place Royale for a moment, in order that her husband might have had some confidence in her to whom he owed the great confidence of not being found guilty before the ecclesiastics, and which was, so often, more especially on account of the infallibility of the order in all things, and the necessity of always returning to that place with her when she was ordered to stay at home or draw up a letter, which had been in the Rue de Vaugirard; but, fortunately for Milady, her husband was not the less a cardinalist who made himself the cause of scandal, because at the moment when she entered the Rue D’Arons-Épède he came to the very castle of the Holy Father, as has just been told, with the Duc d’ Anville in the closet, and the three others, one of whom was the Duc de Richelieu, who was the chief of his household, were the leaders of his corps, in whom he always kept a secret which he never revealed even to D’Artagnan, as no one who knew or cared to know him could have hidden it from his eyes, or from his heart, and as his hatred for Aouda was so strong, notwithstanding his cardinalist prejudices, that the king at the present day it is said he was all the rage of his heart not to give back to him all that he was due, or to spare him the trouble of sending him home for such a great devotion and as the present; but the moment when he found himself, and found himself as a prisoner, or rather as a prisoner in a province, as I have described, it struck him with a strange idea that if this pretended liberator had been killed it would have seemed strange to him, how it must appear to all who were present.” “But I tell you I think it rather strange.” said Athos and D’Artagnan, in a whisper that was not quite secret, for he had already said to himself that it was nothing more than a desire of vengeance against the cardinal as the cause of his suffering, and even more strange to him that the queen would have no reason to believe that such a liberator existed; “but I was obliged to do what he asked of me in my own interest, and I am grateful that I was obliged to do it.” “That is true, my Lord, and it is also true with men.” “That is also true, my Lord.” “But that’s not all; all the more strange, it seems, because it would be almost as natural to me to believe the reality were not so much.” And, “But then my lord,” continued D’Artagnan, in an embarrassed tone, “you would not believe, when you hear me,” said he, after the fashion of an officer, “only that there must have been a cause for it upon the whole.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the model to evaluate to run prompts on the model for generation\n",
        "model.eval()\n",
        "\n",
        "prompt_text = '''Nihara the warrior princess was calm in the face of danger.\n",
        "No one dared challenge her now.\n",
        "'''\n",
        "\n",
        "\n",
        "#Convert the prompt text to tokens and add the attention mask\n",
        "input_ids = tokenizer(prompt_text, return_tensors = \"pt\").input_ids\n",
        "attention_mask = tokenizer(\n",
        "    prompt_text, return_tensors=\"pt\"\n",
        ").attention_mask\n",
        "\n",
        "#Send converted prompt and attention mask to GPU\n",
        "input_ids = input_ids.to(device)\n",
        "attention_mask = attention_mask.to(device)\n",
        "\n",
        "\n",
        "#Generate the output from the model based on the parameter set here\n",
        "output = model.generate(\n",
        "    input_ids = input_ids,\n",
        "    attention_mask = attention_mask,\n",
        "    pad_token_id = tokenizer.pad_token_id,\n",
        "    max_length = 1024,\n",
        "    num_beams = 10,\n",
        "    min_length = 1000,\n",
        "    temperature = 3.5,\n",
        "    top_k = 50,\n",
        "    do_sample = True,\n",
        ")\n",
        "\n",
        "\n",
        "generated_text = tokenizer.decode(output[0],skip_special_tokens = True)\n",
        "\n",
        "\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WnaAreSubBg",
        "outputId": "7c69264d-527d-43a6-c0e1-b1f02721c4f2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nihara the warrior princess was calm in the face of danger.\n",
            "No one dared challenge her now.\n",
            "“But you are a man, I guess,” said the king, “and if you try to escape, I forbid it!” No one ventured against him, even the king, who had his finger on the trigger of his own wish! All who tried to stop him were crushed by his powerful arms and crushed to death! The king was in his death throes! He was in agony the instant before his death, and yet he had just succeeded in stifling a little ray of hope in the queen’s eyes! She knew that he was doomed to disappointment, but this time it was his own! She kept on praying that God would bestow blessing on her life, but the ray fell from her eye while it was floating close to the door of the Nautilus’s interior! She longed for a moment when we could go back to Nantucket, one last visit to our old homeland! “But how am I to escape if my Nautilus is lost?” she said in a voice trembling at the prospect of ultimate destruction! The king and I shared her fears, and for three hours we stared in abeyance, each expecting the other’s order to return to its hôtel and start for the far seas! Meanwhile I had thought out my last plan, but it was nothing but a riddle that concerned only myself and the king; it was simply a desire to sleep on board until the Nautilus was afloat and ready to return to shore! Captain Nemo slept peacefully—for the next two and a half days! In a calm it seemed a thousand times more tranquil than when I and the queen were imprisoned inside the Nautilus!   And now that the sea was no longer her domain, where could I go to escape? At least we would have time to think about escape! “If it were up to you, Ned my friend,” I said to myself, “I wouldn’t have an escape attempt until I knew for sure that we had everything we wanted and needed, and that I had nothing to fear from the dangers lurking on board! But in the end it was certain that we would come ashore in one piece! Ned Land was right,” I answered the king in the most peaceful voice I could think! And yet I couldn’t come up with the boldest plan! Then Ned Land, never one to be easily intimidated, calmly told me the following day: “I think, then, that the king has a narrow escape out there that I’m unable to pass up!” The Nautilus lay no more than 150 meters beneath the waters of the Pacific Ocean, and we no longer knew where it went! Perhaps it went, and might be lurking there for entire days—perhaps even for whole months, months! Was the captain uncertain as to which way this Nantucket seemed winding up! I no longer knew! I no longer dreamed of escaping! Then Ned Land turned to me full of hope and said: “Master is counting on you.” I readily granted his request, although it seemed impossible to me at that time that the king had any intention of prosecuting our escape efforts! Was the way in which Ned Land had! I followed? Was it really feasible that he would risk everything just to slip away with us on a whim like that, when that man already had thrown fifty pounds of gold under our noses! I consented that he might try the trick—as rashly as someone might try a poisoned dart—and then quietly resign myself to following the trail wherever it led, whenever it led, on shore or underneath the seas! Ned Land smiled to me as he spoke, and in another minute I felt the dart leave my fingers and fell like one more flea into a corner of the Nautilus! No more darting ever seemed in store for me! Where was Ned Land, master? Where was master? I was in utter despair, but I knew that the king wanted my Nautilus back, and it was already nigh to leaving the Nautilus and sailing back to Nantucket! It seemed that the king wished to visit this enchanted island when it rolled up behind the shores of England or the Continent! So did I! There was one thing I had to take from this strange dream! I had a dream! Then I had a dream of our lives being swept out of those waters! What was going on here in those deep waters, those seas where our lives were hanging in jeopardy in jeopardy! The unknown sea seemed as dangerous as the unknown monster it had chased us! I was alive! At least Ned Land had determined plans for my escape! I must go back to the seas of Nantucket! And right then I felt that a dreadful doubt haunted me.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the model to evaluate to run prompts on the model for generation\n",
        "model.eval()\n",
        "\n",
        "prompt_text = \"And so it was the beginning of a beautiful friendship. Perhaps even something more. \"\n",
        "\n",
        "#Convert the prompt text to tokens and add the attention mask\n",
        "input_ids = tokenizer(prompt_text, return_tensors = \"pt\").input_ids\n",
        "attention_mask = tokenizer(\n",
        "    prompt_text, return_tensors=\"pt\"\n",
        ").attention_mask\n",
        "\n",
        "#Send converted prompt and attention mask to GPU\n",
        "input_ids = input_ids.to(device)\n",
        "attention_mask = attention_mask.to(device)\n",
        "\n",
        "\n",
        "#Generate the output from the model based on the parameter set here\n",
        "output = model.generate(\n",
        "    input_ids = input_ids,\n",
        "    attention_mask = attention_mask,\n",
        "    pad_token_id = tokenizer.pad_token_id,\n",
        "    max_length = 1024,\n",
        "    num_beams = 10,\n",
        "    min_length = 1000,\n",
        "    temperature = 3.5,\n",
        "    top_k = 50,\n",
        "    do_sample = True,\n",
        ")\n",
        "\n",
        "\n",
        "generated_text = tokenizer.decode(output[0],skip_special_tokens = True)\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "QlDLmZFWug1h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76ca73cd-b55e-40fd-d450-9c7646142834"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "And so it was the beginning of a beautiful friendship. Perhaps even something more.                *       *        *        *         * Once upon a time, a very long time ago now, about last Friday, Winnie-the-Pooh lived in a forest all by himself under a very old tree, and he kept looking up at the sky and saying \"_Is it Cloudy?\" and \"_Oh, it's Cloudy\" and \"_I wonder what's that mean?\" And \"_Heffalumps_\" and such like, and nothing seemed to please him, so he turned round and said \"Are you sure it's not Cloudy?\" and \"_I'll_ look up.\" And then he put his nose to his mouth and said \"Is it Fogglier?\" and \"_I'll_ tell you what it is.\" And he put his nose to his mouth again and said \"Is it _awful_?\" And at last he said, after a long time, \"I wonder what's happened to it?\" And he put his nose to his mouth again and said \"I'll give you a bit of _Ow!\" And he put his nose to his mouth and said \"A lot of_ ow!\" And then he put his nose to his mouth and said \"A very big_ pot of_ honey!\" And he put his nose to his mouth and said \"A very lucky_ thing_ that happened to it!\" And then he put his nose to his mouth and said \"I'll give you a box of _Ow!\" And he put his nose to his mouth and said, in a very loud whisper, \"I found an                 *     *   *     *      *      *      *      *       * When it was last Friday, Pooh lived in a forest all by himself under a very old tree, and he kept looking up at the sky and saying \"_Is it Cloudy?\" and \"_Oh, it's Cloudy_\" and \"_I wonder what's that mean?\" And \"_Heffalumps_\" and such like, and nothing seemed to please him, so he turned round and said \"Are you sure it's not Cloudy?\" and \"_I'll_ look up.\" And then he put his nose to his mouth and said \"Is it Fogglier?\" and \"_I'll_ tell you what it is.\" And he put his nose to his mouth again and said, \"Is it _awful_?\" And he put his nose to his mouth and said, \"I found an                         *    *     *        *       *         * Christopher Robin lived in a forest all by himself under a very old tree, and he kept looking up at the sky and saying \"_Is it Cloudy?\" and \"_Oh, it's Cloudy_\" and \"_I wonder what's that mean?\" And \"_Heffalumps_\" and such like, and nothing seemed to please him, so he turned round and said \"Are you sure it's not Cloudy?\" and \"_I'll_ look up.\" And then he put his nose to his mouth and said \"Is it Fogglier?\" and \"_I'll_ tell you what it is.\" And he put his nose to his mouth again and said, \"Is it _awful_?\" And then he put his nose to his mouth and said, \"I found an                         *     *        *        *        * Christopher Robin lived in a forest all by himself under a very old tree, bright tree, and he kept looking up at the sky and saying \"_Is it Cloudy?\" and \"_Oh, it's Cloudy_ and \"_I wonder what's that mean?\" And \"_Heffalumps_ and such like, and nothing seemed to please him, so he turned round and said \"Is it Fogglier?\" and \"_I'll_ look up.\" And then he put his nose to his mouth and said \"Is it                       *    *    *       *     *      * Christopher Robin lived in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the model to evaluate to run prompts on the model for generation\n",
        "model.eval()\n",
        "\n",
        "prompt_text = \"Thine eyes shine like bright diamonds\"\n",
        "\n",
        "#Convert the prompt text to tokens and add the attention mask\n",
        "input_ids = tokenizer(prompt_text, return_tensors = \"pt\").input_ids\n",
        "attention_mask = tokenizer(\n",
        "    prompt_text, return_tensors=\"pt\"\n",
        ").attention_mask\n",
        "\n",
        "#Send converted prompt and attention mask to GPU\n",
        "input_ids = input_ids.to(device)\n",
        "attention_mask = attention_mask.to(device)\n",
        "\n",
        "\n",
        "#Generate the output from the model based on the parameter set here\n",
        "output = model.generate(\n",
        "    input_ids = input_ids,\n",
        "    attention_mask = attention_mask,\n",
        "    pad_token_id = tokenizer.pad_token_id,\n",
        "    max_length = 1024,\n",
        "    num_beams = 10,\n",
        "    min_length = 1000,\n",
        "    temperature = 3.5,\n",
        "    top_k = 50,\n",
        "    do_sample = True,\n",
        ")\n",
        "\n",
        "\n",
        "generated_text = tokenizer.decode(output[0],skip_special_tokens = True)\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DD5E6kiNud-1",
        "outputId": "11c4ca10-7d31-4225-f27e-6465a72ad499"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thine eyes shine like bright diamonds, Thou and I are alike, And though we be two, yet we’ll make thine and mine eyes sell, Henceforth make them fair by make’s which might not be bought now, Besides these there are ten thousand like me, Which must be made into ten thousand like hands; Henceforth make them fair by make’s which might not be bought now, Besides these there are ten thousand like me, Which must be made into ten thousand like hands.—I would not, thank heaven, That any heart should wish me to part with my skin, That any ear should listen to my tongue! I would not, thank heaven, That any hand should wish me to part with my tongue!—I would not, thank heaven, That any heart should wish me to part with my cheek!—I would not, thank heaven, That any cheek should wish me to part with my cheek!—I would not, thank heaven, That any hand should wish me to part with my thumb!—I would not, thank heaven, That any heart should wish me to part with my thumb!—I would not, thank heaven, That any one should look at me!—I would not, thank heaven, That any one should touch me!  Enter Benvolio and Servant with a torch, with cords Making a noise of “Let us overhaul the table,” and moving about the benches with a “Come hither, gentlemen.—What’s here? a tall man, a dark man, a brawny man, A hand that looks like a bear, with a scar upon his face, A hand that looks like a fiddle-boy, And a leg that’s as red as blood, holding an an anvil, a spade in his hand, A spade in his hand, and a hammer in his foot:—Come hither, gentlemen.—If thou couldst not find the ground, let us overhaul the table, And find the murderers here!  Enter Servant with a torch, with cords Making a noise of “Let us overhaul the table,” and moving about the benches with a “Come hither, gentlemen.—What’s here? a tall man, a dark man, a brawny man, A hand that looks like a bear, with a scar upon his face, A hand that looks like a fiddle-boy, and a leg that’s as red as blood, holding an an anvil, a spade in his hand, A spade in his hand, and a hammer in his foot:—Come hither, gentlemen.—If thou couldst not find the ground, let us overhaul the table, And find the murderers here!  Enter Servant with a torch, with cords Making a noise of “Let us overhaul the table,” and moving about the benches with a “Come hither, gentlemen.—What’s here? a tall man, a dark man, a brawny man, A hand that looks like a bear, with a scar upon his face, A hand that looks like a fiddle-boy, And a leg that’s as red as blood, holding an an anvil, a spade in his hand, A spade in his hand, and a hammer in his foot:—Come hither, gentlemen.—If thou couldst not find the ground, let us overhaul the table, And find the murderers here!  Enter Servant with a torch, with cords Making a noise of “Let us overhaul the table,” and moving about the benches with a “Come hither, gentlemen.—What’s here? a tall man, a dark man, a brawny man, A hand that looks like a bear, with a scar upon his face, A hand that looks like a fiddle-boy, And a leg that’s as red as blood, holding an an anvil, a spade in his hand, A spade in his hand, and a hammer in his foot:—Come hither, gentlemen.—If thou couldst not find the ground, let us overhaul the table, And find the murderers here!  Enter Servant with a torch, with cords Making a noise of “Let us overhaul the table,” and moving about the benches with a “Come hither, gentlemen.—What’s here? a tall man, a dark man, a brawny man, A hand that looks like a bear, With a scar upon his face, A hand that looks like a fiddle-boy, And a leg that’s as red as blood, holding an an anvil, a spade in his hand, And a hammer in his foot:—Come hither, gentlemen.—If thou couldst not find the ground, let us overhaul the table, And find the murderers here!  Enter Servant with a torch, with cords Making a noise of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the model to evaluate to run prompts on the model for generation\n",
        "model.eval()\n",
        "\n",
        "prompt_text = \"Fly you fools!\"\n",
        "\n",
        "#Convert the prompt text to tokens and add the attention mask\n",
        "input_ids = tokenizer(prompt_text, return_tensors = \"pt\").input_ids\n",
        "attention_mask = tokenizer(\n",
        "    prompt_text, return_tensors=\"pt\"\n",
        ").attention_mask\n",
        "\n",
        "#Send converted prompt and attention mask to GPU\n",
        "input_ids = input_ids.to(device)\n",
        "attention_mask = attention_mask.to(device)\n",
        "\n",
        "\n",
        "#Generate the output from the model based on the parameter set here\n",
        "output = model.generate(\n",
        "    input_ids = input_ids,\n",
        "    attention_mask = attention_mask,\n",
        "    pad_token_id = tokenizer.pad_token_id,\n",
        "    max_length = 1024,\n",
        "    num_beams = 10,\n",
        "    min_length = 1000,\n",
        "    temperature = 3.5,\n",
        "    top_k = 50,\n",
        "    do_sample = True,\n",
        ")\n",
        "\n",
        "\n",
        "generated_text = tokenizer.decode(output[0],skip_special_tokens = True)\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "2cMPL-ASugmp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f982e5a4-41a7-4367-de1e-c5aaf7711692"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fly you fools! I say, fly, fly!  [_Flourish._] So ho! O most un-English of men! I was changeling, and it was in vain I could contrive to keep back the change that was making upon my poor, green-blooded, livid spit; it was in vain that I could persuade myself that the alteration was accidental, or that the murderer was a mere fool, for all that! So ho! This trick may chance to scathe you, may it not! But at least, be sure of what you say! You are in the wrong, Englishman; for I speak French, and a man in the wrong does not speak French.” “Go to! Go to!” said the young man, pressing his companion’s hand again with a firm, lingering look, as if this was too much to be borne, and raising his glass in the air a little as if to beg pardon on the part of the two lackeys, with whom he was conversing in an almost condescending, obsequious manner, “you are French! Why should you not? You speak French because you are of decent parentage, and I can understand you?” “Why no,” replied Planchet, turning to the two murderers, “I only ask, on your part, why you are here.” “Why?” cried the young man, in a voice of the most terrible gravity, “and I reply, with the last of my proofs of courtesy, that it must have been for my good interest—but it would be for my sake that you should kill me—for I am on the wing of a gentleman who is the cardinal, and who has sent you to see me—I, who have all the honor of your company here,” added, throwing his eyes on Athos, “who is a Musketeer—for what purpose, then?” “He has sent you!” said Athos; “and he has offered you, I will confess, a large sum—but you refused—why should he ask, when I am here today? But if we were not speaking of the cardinal—what reason then?” “Because I had sworn in the secret—” “But I have sworn it is true!” cried Athos, throwing himself on one side, holding out his clenched fist as if to raise the issue of the two lackeys against it—“and that was all, so soon as his eyes met mine—now his lips met mine—on every side—now his teeth were met with mine, and he drew them away—and yet he hung upon me, as on me, like an iron-cloak!” (his body, which was drawing nearer to his face, so far as to touch the ground.) “If I had not fallen helplessly—if I had but remained in my seat and had been a little less—” he would have said to him, “the two lackeys who held me would have killed me.’—“Then what is your revenge?” said he, holding out his stiffened hand for a blow—“what is my revenge?—for, in the eyes of a fanatic, I could not see to see even the hair; no, could I assure you, I did not see the hair.’—“Ah, then! it is only a simple desire, to be sure, that all that is wanting must have happened.’—What is it that he wishes to have?’t he wishes for rather wishes for something else?—he wishes that he wishes for nothing more than to see me—what is that?—he wishes to have nothing more then?” “Ah, ah! you love me, I love you so! I should rather have seen you half a dozen years ago! Then you would have been less—then it would have seemed just—but now it would be a whole year before I would be sure of you, then, and then, all the more.” The lackeys, listening to the young man, murmured a sigh which must have indicated—“Well, then, what are you anxious about?” “Then you are mistaken—you would have loved me half as much if the cardinal were there, and now he would be sorry for it as soon as he had left you.” They looked at each other without speaking, as they might have seen something in the eyes of the three men in a united state of mind which no doubt they were about to struggle with each other for the smallest advantage; and a feeling of sympathy perhaps prevailed upon one of them—“No doubt it does—but it will never come about then.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the model to evaluate to run prompts on the model for generation\n",
        "model.eval()\n",
        "\n",
        "prompt_text = \"The underground passage led to heaven\"\n",
        "\n",
        "#Convert the prompt text to tokens and add the attention mask\n",
        "input_ids = tokenizer(prompt_text, return_tensors = \"pt\").input_ids\n",
        "attention_mask = tokenizer(\n",
        "    prompt_text, return_tensors=\"pt\"\n",
        ").attention_mask\n",
        "\n",
        "#Send converted prompt and attention mask to GPU\n",
        "input_ids = input_ids.to(device)\n",
        "attention_mask = attention_mask.to(device)\n",
        "\n",
        "\n",
        "#Generate the output from the model based on the parameter set here\n",
        "output = model.generate(\n",
        "    input_ids = input_ids,\n",
        "    attention_mask = attention_mask,\n",
        "    pad_token_id = tokenizer.pad_token_id,\n",
        "    max_length = 1024,\n",
        "    num_beams = 10,\n",
        "    min_length = 1000,\n",
        "    temperature = 2.5,\n",
        "    top_k = 50,\n",
        "    do_sample = True,\n",
        ")\n",
        "\n",
        "\n",
        "generated_text = tokenizer.decode(output[0],skip_special_tokens = True)\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "vaOosc_WugZP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1f7fb90-16cd-46f9-d870-422b5f166d8a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The underground passage led to heaven, and was guarded by a mighty army of angels, who had to do with it in the most economical and regular way.” “But what can these creatures do with such powerful arms?” “They’ve no sails,” Conseil said, “and no propeller, either.” “Oh!” the Canadian put in, “no matter how powerful their engines, they won’t be able to put a sail on a Nautilus.” “Oh, no, Conseil, no,” I answered, “and you’ll never convince me they wouldn’t!” “When I say powerful,” the Canadian went on insistently, “I mean it.” “But the Nautilus has no hatches!” “Yes, Conseil, but it has air tanks!” “But how can these air tanks supply enough oxygen to the Nautilus?” “Without putting it in the air!” “Without putting it into the air!” Conseil answered, staring hard at me for a long time, “at least to the extent that it can escape from it’s underwater fate!” “True, but the Nautilus doesn’t need air to breathe! If it’s lying at the bottom of the sea, then it’s breathing through that opening into heaven.” “Yes, Conseil, but it doesn’t need oxygen to breathe.” “Yet the Nautilus doesn’t need oxygen to breathe.” “But why not?” “Because the Nautilus’s electric rays couldn’t escape from it!” “True, but the electric rays couldn’t penetrate that opening into the brain, Conseil said, staring hard at me for a long time, and then changing his tone, “_pardieu!_” “_pardieu!_” The Canadian repeated, in a tone of deep conviction, “_pardieu!_” And then he repeated, “_pardieu!_” until the Nautilus was breathing through its opening into heaven! I couldn’t persuade myself that this last sentence was correct, and at last I told Conseil what had just been said, and we went down to the shore where the Canadian had left his Nautilus and was busy loading its ballast tanks and igniting its sodium-rich fuel! CHAPTER 16 The Great North Road THE NEXT MORNING, Conseil and I were on board the Abraham Lincoln, which was due at the Abraham Lincoln’s pier at seven o’clock in the morning, just as Captain Nemo and his companions were departing from the Abraham Lincoln! The Abraham Lincoln was one of Conseil’s fiercer vessels than the Abraham Lincoln, and it seemed even more daunting to me than the Abraham Lincoln because it was wider, higher, longer, and more solidly built—’naturally so, I thought I—and it had a huge crew of more experienced sailors than the Abraham Lincoln, because, to my astonishment, it sported a double hull instead of a single pilothouse on its bows! I saw no sign of such luxuries on board the Abraham Lincoln, save for the rigging that kept the pilothouse on the bows! I saw no sign of smoking boilers or steamers, no sign of furnaces or coal or iron, no sign of any equipment that might have been thought of in prehistoric times! I saw no sign of any watertight bulkheads, no sign of any breathing passages or drains! I saw no signs of any drains! I saw no signs of any steamtight bulkheads, no signs of any drains! CHAPTER 17 The Great North Road THE next morning, Conseil and I went down to the Abraham Lincoln’s pier, a hundred yards from the Abraham Lennox, at exactly half past four in the morning! I was so excited by the sight of this immense craft, by the thought of its enormous weight, and by the thought of its enormous potential! I thought all these things at once, Conseil and I, and we walked for hours together over that immense plain! We walked for hours together over that plain, never minding the past and the future, never minding even the past and the future! I felt all these things at once, Conseil and I, and walked for hours together over that immense plain! CHAPTER 18 The Ice Bank THE NEXT MORNING, Conseil and I were on board the Abraham Lennox, just as Captain Nemo and his companions were departing from the Abraham Lennox! Captain Nemo and his companions seemed even more\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "prompt_text = \"The ray gun vaporized the entire town under the sea\"\n",
        "\n",
        "#Convert the prompt text to tokens and add the attention mask\n",
        "input_ids = tokenizer(prompt_text, return_tensors = \"pt\").input_ids\n",
        "attention_mask = tokenizer(\n",
        "    prompt_text, return_tensors=\"pt\"\n",
        ").attention_mask\n",
        "\n",
        "#Send converted prompt and attention mask to GPU\n",
        "input_ids = input_ids.to(device)\n",
        "attention_mask = attention_mask.to(device)\n",
        "\n",
        "\n",
        "#Generate the output from the model based on the parameter set here\n",
        "output = model.generate(\n",
        "    input_ids = input_ids,\n",
        "    attention_mask = attention_mask,\n",
        "    pad_token_id = tokenizer.pad_token_id,\n",
        "    max_length = 1024,\n",
        "    num_beams = 10,\n",
        "    min_length = 1000,\n",
        "    temperature = 3.5,\n",
        "    top_k = 50,\n",
        "    do_sample = True,\n",
        ")\n",
        "\n",
        "\n",
        "generated_text = tokenizer.decode(output[0],skip_special_tokens = True)\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "8jsVLyp5ugLd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdc45361-37f4-47f0-d6e4-902756283e2c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ray gun vaporized the entire town under the sea’s waves, and the few survivors that still emerged were bathed in blood that had been spattered by the monster’s waves.” “And what did it do once it was afloat again?” “It destroyed all the stores of the town, and forced the remaining inhabitants to subsist on goat or rabbit meat, or on some hardy dry dumpling made from the cuticle of sea lilies, for which my mother had to be provided with a large supply.” “And once it had settled down, what did it do in the meantime?” “It simply drove the town to the ground, demolished everything, and left behind a smoking heap that was sure to be picked clean in the coming weeks.” *Author’s Note: In Chinese legends, a dragon is said to have laid waste to an entire city, just as a company of soldiers does in an old fortress, by crushing it under its fangs: “The bones are the soldiers’ encasements,” and from its final destruction, “The bones are the food!” In this passage, however, the line originally quoted is from the story of an encounter between a Mormon and a dragon, which occurred when Mormon Commander Bowen was commanding in a desert on the Pacific coast: “They were in the middle of the Pacific, cruising in an open boat; I say, cruising in an open boat, as you might say! Here’t happened to meet up with the captain; but, shipmates, what could he do, with such a bulk on board—like a mass of brine from the Baltic or the Orinoco Delta!—could he float off to a floating island? Well, a few months back now, I sailed along the Pacific, at the south-north-east end of the Falkland Islands! and as I went along I chanced to come across a ship wrecked by hurricanes; and just as the wind of that very hurricane came to pass, the sea was covered by a layer of water not even two fathoms above our heads! A few months back, in a similar voyage, also, did I cross a shipwreck whose wreck looked much like an iceberg! But this one, Professor Aronnax, was of an extremely large make, of a colossal bulk, lying on the ocean’s bottom; its keel had been shattered off, and as it rolled away, with the remnants hailing over the surface of the water, its upper portion, as you say, floated away, leaving behind a sea of blood on the sea bottom just beneath it! The blood hadn’t impeded my maneuvers at all; it only strengthened my conviction that we wouldn’t see that boat for many years.’s time to come! Captain Nemo then gave us a last encouraging word, and headed the boat back again to the Nautilus, headed straight for Treasure Island! Captain Nemo took charge of this heroic feat; and even the chief officer was impressed with the coolness and tenacity of Captain Nemo! As for the next hour and hour and a half went by without telling us much more—or offering any complaints to me—until at last his voice grew stronger, and stronger, and stronger, and I heard him say, “No, not tonight! Tomorrow; tomorrow!” _The captain had a long way to windward destiny in store for us, and his stubbornness, and his inexorable resolve, and his iron will to turn his ship around! I could now fancy, too, that for once he would agree to my every one of my plans, or else I would be beaten to a halt; but when his stubbornness grew to that intolerable height, I was resolved to do what he commanded, or was it more than justified, for we were now locked in a circle that would surely mean the destruction of both our chances for salvation and our lives! Oh, Professor Aronnax, why had you not told me the night before the attack! Was not I informed of this beforehand? And then, after we both went inside the Nautilus, Captain Nemo never again spoke to me of “the White Whale,” nor did I hear of other such ships till the very last!” And the last sounds I heard were of the captain, who still looked over his shoulder as we sailed by, as if to see what else he might do, and as if he also would do what he had commanded—“The white whale!_—in truth, it was much more likely that we would encounter him in the South Seas, where our iron moorings lay in those inaccessible reaches of the Atlantic, than on the beaches of those sunny shores of Asia where his iron moorings lay! For I now felt sure that we might be in the same latitude and longitude that Captain Nem\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "prompt_text = \"Kushan, Nadishan and Dilshani were primordial entities that defended the very fabric of reality\"\n",
        "\n",
        "#Convert the prompt text to tokens and add the attention mask\n",
        "input_ids = tokenizer(prompt_text, return_tensors = \"pt\").input_ids\n",
        "attention_mask = tokenizer(\n",
        "    prompt_text, return_tensors=\"pt\"\n",
        ").attention_mask\n",
        "\n",
        "#Send converted prompt and attention mask to GPU\n",
        "input_ids = input_ids.to(device)\n",
        "attention_mask = attention_mask.to(device)\n",
        "\n",
        "\n",
        "#Generate the output from the model based on the parameter set here\n",
        "output = model.generate(\n",
        "    input_ids = input_ids,\n",
        "    attention_mask = attention_mask,\n",
        "    pad_token_id = tokenizer.pad_token_id,\n",
        "    max_length = 1024,\n",
        "    num_beams = 10,\n",
        "    min_length = 1000,\n",
        "    temperature = 3.5,\n",
        "    top_k = 50,\n",
        "    do_sample = True,\n",
        ")\n",
        "\n",
        "\n",
        "generated_text = tokenizer.decode(output[0],skip_special_tokens = True)\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "2sKrOpttuf8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6097058-285e-49ef-a02e-68f2bc396d8a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kushan, Nadishan and Dilshani were primordial entities that defended the very fabric of reality, and they were continuously attacked by their assailants, despite their thousand years of invasions and wars, the centuries since Adam began his mortal existence.” “But this doesn’t account for all attacks.” “Yes,” I replied, “all attacks—homicidal or not, perpetrated by hostile elements or by human beings.” “There is an absolutely inexhaustible book in English which treats of every type of attack on man—homicide and suchlike—in hundreds of different forms, and in countless languages.” “But this doesn’t take into account the vegetating and multiply multiply malicious creatures that exist outside the earth, such as the amazon, the gibbering mollusk, and the new-hatched whale.” “Yes, but there is a translation of that work in several languages,” the harpooner replied, pointing to a leaf in the back of the _Voyager_: “The _Apes_.” “An _Apes_!” Ned Land answered in all seriousness, his eye ablaze, staring at the whole creature with a singular look, as if it were too large for him to comprehend its dimensions; “just so, the _Apes_, then, is the _English_, although it must have come from the French; _Apes_, in fact, is pronounced _French_.” I read the whole _Apes_ aloud, and felt my heart leap in my chest when I felt its length, when in fact it was only two thousand five hundred and fifty miles long—nearly half of which was the original manuscript of the _Apes_, or rather, from a double-bound Dutch copy!” “Apes!_ “We’ll soon settle this subject,” the Canadian replied, after a few minutes of silence.* *Latin: Apes are sea turtles whose eggs hatch directly from the females, and it takes them to the mid-Atlantic, where they have a long interval from their wintering grounds in the north and south, where they’re mostly encountered year-round.* I saw Conseil’s eyes flickering over the surface of the sea upon that text; and I myself couldn’t stand the staring scrutiny of those eyes, even with Ned Land’s penetrating eyes! The question was a real enigma to me, and when I was led to answer it by the Canadian, the former sank into a stupor of disbelief, his brow slightly sunken, his teeth a thin brown, “Utopian” on his upper lip; and the latter, as if regarding my reply with a sad irony—”—after all, he had a good grasp of Latin and Greek—asked me what “we’re looking for here, Conseil.” CHAPTER 2 The Leviathan THE NEXT DAY, April 11, I walked over to the open deck, which was shaped like a huge fishing lance, in the centre of the bay, and rested for a good hour, resting on my elbows, while watching the battles over the bulwarks, to see the newcomers once more, while the Nautilus passed by the Nautilus on its long voyage along the whole stretch from Cape São Roque coast, from the tip of Brazil to the shores of Peru, and from Lima to Porto de Janeiro, where the Portuguese Villeros settled down after the victors of the war.* I saw Conseil’s eyes flickering over the sea at the view I had so long ago taken, and I asked him politely if he knew why Conseil was so gloomy, so anxious for the world’s wonders! The Canadian shrugged his shoulders, amused at my curiosity, while Ned Land, Conseil, and I laughed heartily, on seeing that all was not lost, went below to work on the pumps.* The next morning, however, when everything would be unveiled to them, they would take to their work like villagers in a village, devouring their refuse like pheasant and eating it up in glee.* THE NEXT MORNING, Conseil, working with his friend Ned, and a host of hungry harpooneers, walked over to the bows of their boats, ready to start off at once for a stroll on their treetops! CHAPTER 3 The Whale CHAPTER 3 THE MORNING, while the pilothouse was vibrating, the boat’s two bows and sterns shook as if the planks were splitting, and their masts, like windlass, whipped back and forth between their keels! CHAPTER 3 THE SAME THE next morning, just as dawn had dawned, I walked up and down to the cabin,\n",
            "Kushan, Nadishan and Dilshani were primordial entities that defended the very fabric of reality from the thrusts of the destroyer’s thrusts! What a lesson was this to me! How could I ever escape from the reality of my own slumber! How could I sleep at ease in my own skin! What would I do while Captain Nemo took me around the world in eighty days? I would go back to my own country! Never! Then I would return to my little cubicle, unfast with all my precautions, free my treasures, and sleep like a true citizen! Never! Until then would I spend my time on the run! Admitting that my intellect was half of what it was capable of, I pitied my fears! The Nautilus lay motionless on the ocean, its gigantic hull glistening, its propeller kicking the waves! Perfect! Perfect! It seemed to be descending to the lower strata, straddling the lower strata of the earth! Perfect! But all the while, the earth beneath me shivered beneath the surface of the waves, the earth beneath me was slipping beneath the surface of the waves! My heart sank within me! The Nautilus lay no more, because my body had been too much detached from it—too much detached from the ocean, the ocean, and my heart had long since left it! So, from the point of its starting, it retreated with inexpressible speed, leaving me to scour the bottom with inexpressible tenacity! How could it have moved from this bottom to this bottom, from that bottom to that bottom, from this deeper to this lower? Was it returning from a whirlpool inlet to this gulf, from somewhere deep down beneath this gulf? I felt certain that it was approaching me! But now the mystery deepened, grew deeper! Was this Atlantis returning from a submerged cavern to an underground cavern! I was plunging my every soul into its den, and from the bottom of my heart, I was sucking in my every soul! Meanwhile, Ned Land, deprived of any contact with the surface, had missed a whole lifetime of my own! Had he had no clue to what was going on! What an enigma! Was he, Ned Land, unaware of what was passing between us, unaware of where we might be heading to! What a mystery! I felt hopelessly lost! Meanwhile, during those hundred days, I had gone about my chores like any good citizen! I ran to my fish tank at the surface of the waves, I washed out my polyps and cleaned my eggs, I washed my hands, I washed my face—I did all this in the name of my fellowmen! Where were we going? I was not sure! I was dreadfully afraid! But how could we escape from the truth of our situation, from the mystery of our circumstances? Would Ned Land’s leadership, or my Captain’s leadership, in whose absence I had no clue! What was Captain Bildad doing in my absence? Would he, Bildad, at least, be going on shore with me at all? No, I was sure! Meanwhile, I had no desire for anything from shore, no interest in spending my time on shore, in any social contact except that could possibly divert me from my voyage! For in the direction I was heading! No! And in a direction so solitary! All these things were out of my customary sphere! I had no desire, indeed, no desire for anything from far away—I wanted nothing in the direction I was heading! My thoughts ran on the broadening of the horizon! Whole continents seemed to be creeping closer and closer and closer to me! Where, on the one hand, stretched the great ocean seemed closed off to my sight! Was this world really closed off to me, a world so different from my own reality, an unreachable paradise in the middle of the sea? Never! Never! I realized that my dreams of freedom were fading away! I felt that for the next twenty odd days I had lived in a dream! Was my waking life some sort of dream, or was it only a dream, a mirage, a nightmare that was passing behind me on the other side! A mirage! As I stared about me, I was amazed at the strangeness of this whole world! But it must be, I thought, that these latter days of mine were waking, waking up for a moment in a strange land of the unknown! Was this dim, dim world of this unreachable world, that it was passing before me, a sepia painting of the distant future, as though from afar! But no! What was passing before me, that this serenity was passing in this enchanted air! Was I! It was no longer in the ocean, it was inset in this placeless air! But this insetness was so different from the glimmering sea of the sea, that every plank, plank, seemed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "prompt_text = '''Nihara, Suj and Janu wielded the powers of the kingdom. They were the fairest and most beautiful princesses ever seen. '''\n",
        "\n",
        "#Convert the prompt text to tokens and add the attention mask\n",
        "input_ids = tokenizer(prompt_text, return_tensors = \"pt\").input_ids\n",
        "attention_mask = tokenizer(\n",
        "    prompt_text, return_tensors=\"pt\"\n",
        ").attention_mask\n",
        "\n",
        "#Send converted prompt and attention mask to GPU\n",
        "input_ids = input_ids.to(device)\n",
        "attention_mask = attention_mask.to(device)\n",
        "\n",
        "\n",
        "#Generate the output from the model based on the parameter set here\n",
        "output = model.generate(\n",
        "    input_ids = input_ids,\n",
        "    attention_mask = attention_mask,\n",
        "    pad_token_id = tokenizer.pad_token_id,\n",
        "    max_length = 1024,\n",
        "    num_beams = 10,\n",
        "    min_length = 1000,\n",
        "    temperature = 3.5,\n",
        "    top_k = 50,\n",
        "    do_sample = True,\n",
        ")\n",
        "\n",
        "\n",
        "generated_text = tokenizer.decode(output[0],skip_special_tokens = True)\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHlOu82Vufup",
        "outputId": "00fc1493-a26e-46b6-a419-8d760830b39f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nihara, Suj and Janu wielded the powers of the kingdom. They were the fairest and most beautiful princesses ever seen.  [1] An elusive dream, to be sure—the most delightful dream in the world—never occurs to you, to me—” “But what does it mean?” “It means I have only one life to pursue—the kingdom I have inherited from my father; but if this life is lost, it won’t be because my companions have abandoned me, but because the king and queen have stolen it from me, a life I renounced ages ago.” “How can this be?” “Because they recognize the power of these three valiant knights, and they will not let me leave their service just for a week, without offering me what they claim is a complete reward.” This time the countenance of Milady changed with the rapidity of lightning; she could scarcely realise the depths of surprise, and when she thought the king and queen were plotting her overthrow, a feeling of terror came over her which she never could have known before! As to the thing I said to her at this moment, I was not even half sorry that my secret should make itself known to the king and queen, and it is the queen whom I accuse in this manner! “Well, what can I do to save her, then?” “You must write to the chancellor and the consul at Amiens, and report to them that I demand the return of my head and the hands on my pistols to the queen, and that you know that they have a right to my life.” This was impossible; the king and queen would have punished me, if they could read my thoughts! But the chancellor took pity on the poor girl and wrote—” A letter! What dost thou say!” A letter from the queen, who, according to a custom in Spain, had sent letters on all occasions to the principal towns in order to see all her friends and affairs, but found here at the convent a little place for herself alone? This time the eyes of the young officer darted toward the letter; it was a reply from the late queen to Anne of Austria who, according to custom (she believed), had written to him upon the day of the attack of the enemy with her sister-in-law; it contained the names and the address of Messieurs Dessessessart, and the duke of Buckingham, the heir to the throne who would be happy in the presence of the king on the day of the victory! Did the victory belong to the queen herself? No, the queen—for this time D’Artagnan, not the king, gave the honor to the kingdom with which the Duke of Buckingham looked on, and upon which she would be happy in the sight of him! Do you, D’Artagnan! And in the name of Athos I grant you, I declare that I did not know this young man, and if you are a man you were not, you must tell me, or I would not understand it; but if you were, it would be the height of folly to doubt.”—he repeated these words all in a scream, as if he could think of himself—’d he had received it in his head, “an insult.’ll be as bad for you,”—“Yes, so it seemed to me; for in my heart I felt like I had never seen men act so selfishly before, or acted so selfishly since, and if I could understand this young man truly did it, it, it would be an insult to both D’Artagnan and himself! But, by my soul, I was not convinced of this in the first place, nor could I believe that the queen could be an agent of the cardinal! Did this young gentleman in the presence of a cardinal think-leader, and was it not in the least contrary to the natural instinct of the human heart to wanton? Did I have any suspicions against Monsieur d’Auverne, who, at a later date, we saw with regret, but with so much emotion and mistrust in his Eminence? But I have now the proofs that it was the cardinal—the proofs which he sought—that is, the proof from his own lips, which are in the hands of men as much removed from it as they are from those of the cardinal! Did you, and could it not have happened that this young man, in his heart, wished to see you as we see you? Was he not then thinking of yourself? Was this young woman when he was standing on the street corner of the Rue aux Ours? Did this young woman then have anything in his heart that made him feel sad, as you would have believed us? Yes, this young woman had come from the Rue aux Ours\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "prompt_text = 'Aragon and Frodo along with Passepartout leapt from the plane'\n",
        "\n",
        "#Convert the prompt text to tokens and add the attention mask\n",
        "input_ids = tokenizer(prompt_text, return_tensors = \"pt\").input_ids\n",
        "attention_mask = tokenizer(\n",
        "    prompt_text, return_tensors=\"pt\"\n",
        ").attention_mask\n",
        "\n",
        "#Send converted prompt and attention mask to GPU\n",
        "input_ids = input_ids.to(device)\n",
        "attention_mask = attention_mask.to(device)\n",
        "\n",
        "\n",
        "#Generate the output from the model based on the parameter set here\n",
        "output = model.generate(\n",
        "    input_ids = input_ids,\n",
        "    attention_mask = attention_mask,\n",
        "    pad_token_id = tokenizer.pad_token_id,\n",
        "    max_length = 1024,\n",
        "    num_beams = 10,\n",
        "    min_length = 1000,\n",
        "    temperature = 6.5,\n",
        "    top_k = 50,\n",
        "    do_sample = True,\n",
        ")\n",
        "\n",
        "\n",
        "generated_text = tokenizer.decode(output[0],skip_special_tokens = True)\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HZxX7yrufNN",
        "outputId": "0d3c3a8f-9924-42c3-b89a-710de9dd6b22"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aragon and Frodo along with Passepartout leapt from the plane into the boat which was now pulling clear of the bank, and then they all three disappeared over the surface of the sea! At the other extreme, the sea submerged to a depth of one mile, as if each man had carried his lantern into the sunset! It was a genuine vertical expanse with lofty buildings stretching up almost at the horizon in the shape of great cities, each a great city surrounded by the arches of gigantic arches! Truly it was an incredible land, the arches waving and growing wide and deep as the horizon, an incredible wilderness of arches seen from such wide strata, where people walked and went, sun or shade, amid this liquid glade as rich in zoophyte and rainbow flowers as near shore, the precious waters they hadhes over which the sea had poured so abundantly, while the green sea had turned red, their colours shifting from a crimson tint to something burnt and bloody, as the woodmen hadkins from the tempering bath had redrawn in the fires of the smoky woods! And on both sides of that open gulf the birds sang, and watched the wild flowers and fowl flock of large birds glide quietly by on their weary flight, without fear, knowing that fear would overtake them in the twilight! “This is close, friend,” sang the captain, “and our plans will succeed,” while one of the sailors stood under a clump fence in the bow and prepared to let them go on their way and ease themselves of a heavy pinch if the robbers had deserted them! There were several branches and fine flowers on that continent, though not quite in the temper of wild rose, as you may easily fancy! And at the other extreme of the space, where these delightful animals had gone to snap a great many flowers and watch their young, what wonder, what an open and tranquil world that was! The three strangers were delighted, heartily delighted; Starbuck loved all three! Then suddenly a new thought crossed his mind whose color seemed to awaken fears to a soul deeply touched, and it was something like the following: “If my master goes down that first dark night, how is it that I feel enchanted and exhilarated, when every emotion is but painful? When is my wife and children safe?” The stranger who had the chain took a good deep sigh, made a sign with his arm that some thought must have offended the man, and then began again with profound sadness: “It is for us, gentlemen, my friend; it would anger my lord if this affair were discovered; I would desert my two faithful companions forever! But with my companions of the four fairies! I have loved so deeply, and what would they know of my crimes against the country? Who knows! There are faithful and true ladies, old wives, and sweet young mothers still living! But to judge from what vile lip-glancing could their dim little eyes ever see, let old life go astray! Ah! what dark days and nights I would keep wandering there! I dreamily imagined! Where hearts would beat with love! An anger so intense could burst like fury! If passion threw its shroud about this poor creature whose passion was its secret! This is howling! Yet could love think of itself so free! Away passion’s fatal conceits, here! But who says love can be unadvised! Love has no need of supervision, no excuse of it! If it can have such a lofty motive as passion to follow, why should love escape such a perilous route to escape! The bird, on its side, loves the sea where it can go, not vice, as life itself doth, being but an ardent spirit! Love is like an envious spirit, and as passion a furious spirit! So with passion there is anger towards death! Death too—for death is as an active spirit! Ah, well! what fear could hide passion from death so passionate, why should love hide passionate things! Here, men, I can find love in spite of passionate passions! If love has wings to hide, as flaming birds of flame would fly! Now it comes out! What man could have hidden passion but that which had fled to escape the chase, which escape the fear? What could hide the beloved if it were still loved; if all were alive, as men love in the whale! As with the birds who fly, love flies forth, and loves out! As with their beloved bird! Ah! what great things in life cannot be feared at times, and what dreadful times, like those hideous things! It seemed to her a terrible, dreadful ignorance; so did Jonah! Had the monster been like a tiger who would have the wind to blow, if he had wings and sails! Was it then; was he strong enough to flee, then, with Jonah! What could fright his soul have? There he lies! The heartless spirit fled from him, that was the fear! Then\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "prompt_text = \"Great Scott!\"\n",
        "\n",
        "#Convert the prompt text to tokens and add the attention mask\n",
        "input_ids = tokenizer(prompt_text, return_tensors = \"pt\").input_ids\n",
        "attention_mask = tokenizer(\n",
        "    prompt_text, return_tensors=\"pt\"\n",
        ").attention_mask\n",
        "\n",
        "#Send converted prompt and attention mask to GPU\n",
        "input_ids = input_ids.to(device)\n",
        "attention_mask = attention_mask.to(device)\n",
        "\n",
        "\n",
        "#Generate the output from the model based on the parameter set here\n",
        "output = model.generate(\n",
        "    input_ids = input_ids,\n",
        "    attention_mask = attention_mask,\n",
        "    pad_token_id = tokenizer.pad_token_id,\n",
        "    max_length = 1024,\n",
        "    num_beams = 10,\n",
        "    min_length = 1000,\n",
        "    temperature = 6.5,\n",
        "    top_k = 50,\n",
        "    do_sample = True,\n",
        ")\n",
        "\n",
        "\n",
        "generated_text = tokenizer.decode(output[0],skip_special_tokens = True)\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALUGRvbeqR5o",
        "outputId": "510ebc03-99d8-4b01-afe5-6aa412393d3d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Great Scott! Scott!   That mad man does not walk ’gods,”   But treble-mad he makes the church march!— Come church, march!   Ho! he cannot understand the thought   Avenger he makes alive!— No; yet he shall   Well understand, when I speak of Ahab now: Haul in full gear, swoops a whale   So high that over it there flukes it in half as if from off land; and as for that other two,   Not that are in the chase, yet still alive, in the cabin— That poor devils must have had to   Suffer what the chase has inflicted— So they are safe and sound— Not alive, no—  (_That_ shall be_)—to keep up that old game! Come, thou windy sea   Avenger! And now, windy sea I am thundering off— So shall all men who look on!—  Whom—the wind, as the captain said? So, then, if ever I make any attempt—Come windy! whither, then;—to start him, my men! come   sea again—heave as the sea! now, give me back that prodigious steed (_There_, shall he start); come forth from every head,—   So all sea and all sky! come—more round him!—No more land, more sky; Heave all men—to break open the everlasting chase! come   world—Ahab;  to be a lion! come thy full-sail heaven!  And then!—to fly!—then, earth and earth! all’s water to be thy winged king! Hark ye.—Make thy windiest man—that’s his guise; And go—heave! he lifts us high, with all the might— But never lifts him low! Come, men! this chase is mad; this chase is old and dead; His life is old! this chase—being the lord of all time—had to kill us! Come, take the head off this whale; take this head, away from all sky— For I made a heaven for it!—seems the more just!— Now, from this first head the last will have it,— It seemed fair and fair afore to chase me this way! so,—Now, I want it.—The whale was not a god, then; no soul was living there in that head; He took the fish for that heaven to slay his soul:— To hold his old mast—this one I kill,— Oh! I did nothing to keep him,— I gave it,—to kill myself.—All the fish at once? yes.—Now, well!—he gives himself to him! HE Ahab! I have nothing at all.—It was in the line,—how many heads? Was this shark? No; but—I do not feel but a thing.—What do you? Now, do you have a head at such odds—with that shiver   Here, it cracks like ice! So this head that cracks like the frost on the brain: And this head it must be cracks—like the first thing it ever,  Whence this mortal life-thrown champs it!—I take it.—This be all but a boy,—but who ever was a king, to that had this crown? Now—give the fish, then! (_Well_ then)—who have you but the right  (_Well_There_? then?_) before this throne? Ah! the gods did not come; this one made it into his head—I know what it does— Now then.—Yes, well—this is very fair game,— What was to have it from him! So.—This fish made you the king? Had to have it afore— Had to have—all.—Ah! now—there—now, make the tackles, now.—_There_; how many hooks? had to have every hooks ever? Now, where did you begin—now you do? This line is something; this fish made it.—Then make all men—oh! he made it; no one made it.—O—all men must have the starting —it was it— To be all man! Come forth! come—come!—now I had it already—come away—come forth!—_My last one!_ He came away!—Now it is mine! why were the last ones not yet!  Awake now!—that I had them,— Was it them?  Now have them all ready —I do —_O’er’ing for it! now! now be gone—_Now have them already—now had them all at this! To have their all? Oh! that’ll keep them all! had it.—To keep them—now had there been\n"
          ]
        }
      ]
    }
  ]
}